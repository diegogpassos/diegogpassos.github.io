# Comutação de pacotes, Multiplexação, Enfileiramento

## Comutação de Pacotes

Nas aula anterior, citamos brevemente que a Internet usa um paradigma chamado de _comutação de pacotes_. Entre outras coisas, isso implica que mensagens arbitrariamente longas geradas pelas aplicações são quebradas em unidades menores chamadas de _pacotes_. Em uma rede de comutação de pacotes, portanto, o pacote é a unidade básica de transmissão de dados. Na maior parte das redes de comutação de pacotes, há um limite máximo para o tamanho de um pacote, porém pacotes podem ter tamanho variável (*i.e.*, pacotes diferentes podem ter tamanhos diferentes).

Pacotes são gerados no *host* de origem que transmitidos pela rede até o *host* de destino. Mais especificamente, cada pacote é _encaminhado_ por uma _rota_, *i.e.*, uma sequência de enlaces/comutadores estabelecida entre a origem e o destino. Quando um pacote é transmitido por um dos enlaces da rota, ele é transmitido "sozinho". Mais formalmente, isso significa que:

- Não é possível transmitir dois pacotes simultaneamente.
- Não é possível transmitir "frações" de um pacote: ou ele é transmitido **completamente**, ou **não é transmitido**.

Um corolário desse segundo ponto é que um pacote não também é **recebido parcialmente**. Como também discutido nas aulas anteriores, enlaces podem introduzir corrupções nos pacotes, *i.e.*, determinados bits podem ter seus valores trocados no meio físico. Quando isso ocorre e alguns bits chegam errados, *caso o receptor detecte esses erros*, **todo o pacote é descartado**. Em outras palavras, em uma rede de comutação de pacotes não existem mecanismos para salvar partes corretas de pacotes recebidos com corrupções.

### *Store-and-Forward*

Suponha uma pequena rede formada por dois *hosts*, $h_1$ e $h_2$, e um comutador $c_1$ entre eles. Suponha, ainda, que uma aplicação em $h_1$ gera um **fluxo de pacotes** destinado a $h_2$. Agora pense no primeiro pacote: em certo momento, $h_1$ começa a transmitir os primeiros bits e, após algum tempo, esses bits se propagam pelo meio e chegam ao comutador. Quando esses primeiros bits chegam em $c_1$, o que este comutador faz?

Como ainda há um segundo **salto** no caminho, uma ideia intuitiva seria já começar a encaminhar esses bits para o próximo enlace, de forma a reduzir o tempo total de comunicação. Entretanto, há alguns inconvenientes com essa abordagem. Em primeiro lugar, lembre-se da aula passada que a decisão de para qual enlace saída encaminhar um pacote é baseada em uma **tabela de roteamento** que é indexada por algum tipo de informação presente no pacote. Assim, minimamente, $c_1$ deverá receber esses bits antes de tomar qualquer decisão de encaminhamento. Além disso, é comum que comutadores realizem alguns processamentos básicos sobre os pacotes antes de retransmiti-los pelo próximo enlace do caminho. Um exemplo bastante comum é a verificação de integridade. Embora não entraremos em detalhes sobre esses métodos nesse ponto do curso, podemos destacar por ora que eles necessitam analisar o pacote completo antes de decidir se o mesmo está corrompido ou não. Além disso, lembre-se da nossa definição de comutação de pacotes que pacotes que contenham **algum erro** devem ser **completamente descartados**. Dessa forma, se $c_1$ começa a encaminhar bits pelo próximo enlace, ele corre o risco de notar posteriormente uma corrupção que deveria resultar no descarte do pacote.

Por todos esses motivos, pode ser vantajoso que o comutador espere a recepção do pacote inteiro antes de iniciar o encaminhamento para o próximo salto. Assim, à medida que os bits do pacote chegam ao comutador, esses bits são armazenados em um *buffer*. Quando o último bit é recebido, o comutador aplica quaisquer processamentos necessários sobre o pacote (*e.g.*, verificação de integridade). Em seguida, assumindo que o pacote é íntegro, a tabela de roteamento é consulta e, finalmente, o pacote é encaminhado para a porta de saída adequada.

De fato, essa segunda opção --- de aguardar que o pacote chegue completamente antes de iniciar o encaminhamento --- é comumente adotada em redes de computadores. Em particular, essa estratégia, denotada *Store-and-Forward* (armazenar e encaminhar), é a utilizada na Internet.

Repare que o *store-and-forward* adiciona um pequeno *overhead* de tempo --- *i.e.*, um tempo a mais em relação ao que ocorreria se ele não fosse utilizado. Para ver isso mais concretamente, voltemos ao exemplo do primeiro pacote sendo transmitido de $h_1$ a $h_2$ através de $c_1$. Suponha que o pacote tenha $L = 1500$ bytes e que ambos os enlaces, $h_1\rightarrow c_1$ e $c_1\rightarrow h_2$, operem a $R = 10$ kb/s. Com o uso de *store-and-forward*, o tempo total de transmissão --- ignorando os tempos de propagação --- é:

$$\frac{L}{R} + \frac{L}{R} = \frac{2L}{R} = \frac{2\cdot 1500\cdot 8}{10000} = 2{,}4\;s$$

Agora considere o mesmo cenário, porém sem o uso do *store-and-forward*. Nesse caso, uma vez que os primeiros bits cheguem a $c_1$, imediatamente esse começa o encaminhamento. Isso significa que haverá um certo **paralelismo** na transmissão dos bits do pacote pelos dois enlaces. Assim, ao contrário do que ocorre no caso anterior, os tempos de transmissão do pacote pelos dois enlaces não se somam, porque alguns dos bits serão transmitidos ao mesmo tempo em enlaces diferentes. Isso reduz o tempo total.

Não obstante esse potencial ganho de desempenho, o *store-and-forward* apresenta uma série de vantagens. Ademais, repare que no último exemplo convenientemente assumimos que ambos os enlaces operam a mesma taxa de transmissão. Se isso não é verdade e, por exemplo, o segundo enlace é mais rápido que o primeiro, o comutador pode ter que interromper a transmissão dos pacotes pelo segundo enlace porque os próximos bits ainda não chegaram. Dado que a Internet é uma rede inerentemente heterogênea, esse tipo de situação seria bastante comum.

### Enfileiramento e Descartes

Na seção anterior, utilizamos uma _topologia de rede_ --- *i.e.*, uma estrutura de interconexão entre os elementos da rede --- muito peculiar. Havia apenas três dispositivos dispostos em uma "linha" com apenas um caminho entre os *hosts*. Na prática, as topologias das redes de computadores tendem a ser mais complexas. Em particular, um comutador comumente possui mais que dois enlaces. Assim, uma situação possível --- e comum --- é que dois ou mais pacotes que serão encaminhados por um mesmo enlace de saída cheguem (quase) ao mesmo tempo ao comutador por enlaces de entrada diferentes. 

O que o comutador deve fazer nesse caso? Lembre-se que uma das restrições da comutação de pacotes era que pacotes não podem ser transmitidos simultânea ou concomitantemente. Ao contrário, um pacote precisa ser completamente transmitido para que a transmissão do próximo possa começar. Isso significa que o comutador precisa optar por um dentre os múltiplos pacotes recebidos para encaminhar --- um critério, por exemplo, pode ser a ordem de chegada. Mas o que fazer com os demais?

Talvez a resposta mais intuitiva seja que o comutador deve armazenar esses outros pacotes até que o enlace de saída se torne disponível novamente. Nesse momento, o comutador escolhe um dos pacotes armazenados e realiza o encaminhamento. O processo se repetiria até que não houvesse mais pacotes a serem encaminhados.

Note que, enquanto um pacote é encaminhado por um enlace, é possível que novos pacotes que necessitem ser encaminhados por lá cheguem pelos enlaces de entrada. Assim, esse processo descrito no parágrafo anterior torna-se uma atividade perene do comutador: o pacote é recebido por um enlace de entrada, processado, decide-se por qual (ou quais) enlace(s) de saída ele deve ser encaminhado e, então, o pacote é _enfileirado_ até que chegue sua vez de ser transmitido.

Enfileiramento de pacotes é um dos mecanismos mais importantes de um comutador, e nos Capítulos 3 e 4 desse curso estudaremos com detalhes seu funcionamento. Entretanto, já nesse ponto é importante chamarmos a atenção para uma questão específica: o quão grande é essa fila de pacotes? Repare que o número de pacotes enfileirados tende a crescer a medida que pacotes chegam ao comutador mais rapidamente que o enlace de saída é capaz de transmiti-los --- por exemplo, porque os pacotes chegam por múltiplos enlaces de entrada. Se essa situação se mantiver por um longo tempo, o número de pacotes adicionados à fila continuará crescendo. Mas para armazená-los, o comutador precisa de memória, um recurso finito em qualquer dispositivo computacional. Dessa forma, o tamanho máximo da fila é, também, limitado a algum valor.

Como a fila tem um tamanho máximo, isso significa que eventualmente um pacote pode chegar ao comutador é encontrar a fila cheia. Nesse ponto, novamente, o comutador precisa tomar uma decisão. Simplesmente não é possível armazenar mais pacotes. Logo, a única saída é _descartar_ algum deles --- por exemplo, o pacote que acabou de ser recebido para o qual não há espaço de armazenamento.

O descarte de pacotes é uma realidade na Internet. Na verdade, esse é um evento que ocorre frequentemente --- o motivo disso ficará claro no final do Capítulo 3. Em última análise, pacotes são descartados porque um enlace de saída fica sobrecarregado por um período estendido --- *i.e.*, pacotes chegam mais rapidamente que o enlace é capaz de escoá-los. Entender isso é ponto fundamental para a compreensão de como certos mecanismos que estudaremos nesse disciplina funcionam e por que eles são necessários.

### Comutação de Pacotes: Alternativas

Embora a comutação de pacotes seja o paradigma utilizado na Internet --- e nas redes que a compõem ---, ela não é a única alternativa. Uma dessas alternativas é a chamada _comutação de mensagens_. A comutação de mensagens é bastante similar à de pacotes, com a principal diferença de usar mensagens --- de tamanho arbitrário --- no lugar de pacotes. De fato, a comutação de pacotes é uma evolução da comutação de mensagens que apresenta diversos benefícios, como discutiremos mais a frente nesse curso.

Uma alternativa mais diferente é a _comutação de circuitos_. Um exemplo de rede que utiliza comutação de circuitos é a rede de telefonia fixa tradicional. De forma similar à Internet, a rede de telefonia possui comutadores e enlaces, além dos terminais --- aparelhos de telefone --- que fazem as vezes dos *hosts*. No entanto, os terminais não geram pacotes, mas sim um fluxo contínuo de voz. Dessa forma, se múltiplos fluxos chegam simultaneamente a um mesmo comutador e ambos devem ser encaminhados para um mesmo próximo salto, então não há escolha: ambos os fluxos devem ser encaminhados simultaneamente. 

Para isso, de alguma forma, os enlaces entre os comutadores devem dar suporte a essa transmissão simultânea de múltiplos fluxos. Uma forma de fazer isso é possuir múltiplos enlaces físicos interconectando cada par de comutadores vizinhos --- por exemplo, através de um cabo com múltiplas vias, cada uma permitindo a transmissão de um fluxo.

Independentemente de como isso é feito, existirá um número máximo de fluxos simultâneos suportados por cada enlace entre dois comutadores. Assim, é preciso garantir que esse número não seja excedido, *i.e.*, que um comutador não tenha mais fluxos para alocar para aquele enlace do que ele suporta. Isso é feito através de um processo de alocação de recursos. Ao realizar uma chamada para um certo número de telefone, a rede realiza um processo de roteamento que determina a rota que aquela chamada irá percorrer. Ao longo dessa rota, são reservados recursos, incluindo "espaço" para transmissão por cada um dos enlaces. Se a rede não possui recursos para alocar para a chamada naquele momento, a chamada simplesmente é rejeitada --- por exemplo, através de um sinal de ocupado. Uma vez alocado a uma chamada, o recurso permanece exclusivo, até que ela se encerre. Nesse exemplo, essa alocação de um "espaço" no enlace pode ser simplesmente uma conexão física entre as vias correspondentes dos cabos dos enlaces de entrada e saída.

Embora esse processo tenha sido descrito aqui no contexto de uma rede telefônica, os mesmos princípios se aplicam a outros tipos de rede. Em resumo, na comutação de circuitos: 

1. no momento do estabelecimento da comunicação, executa-se um processo de roteamento e determina-se um caminho;
2. ao longo desse caminho, são reservados recursos para aquela comunicação (*i.e.*, aloca-se um circuito fim-a-fim);
3. os recursos alocados são usados de forma exclusiva por aquela comunicação; 
4. ao final da comunicação, a rede libera os recursos alocados.

Como na comutação de circuitos a rede aloca um circuito dedicado, fim-a-fim, o fluxo não tem qualquer competição pelos recursos a ele necessários. Isso faz com que o desempenho desse fluxo seja totalmente previsível, diferentemente do que ocorre em geral na comutação de pacotes, na qual atrasos podem ser adicionados devido ao enfileiramento. Essa característica é interessante para a telefonia, porque fluxos de voz têm restrições temporais fortes (*i.e.*, eles precisam ser entregues em prazos rígidos).

Por outro lado, a comutação de circuitos também possui desvantagens. Uma delas é a possibilidade de ociosidade de recursos. Suponha, por exemplo, que iniciemos uma comunicação a qual será alocada para um determinado circuito exclusivo. Agora suponha que essa conexão fique um longo período sem gerar dados. Como o circuito está alocado estática e exclusivamente para aquela comunicação, seus recursos ficarão ociosos, porque não podem ser reaproveitados ainda que haja outras comunicações que necessite deles.

Outra potencial desvantagem da comutação de circuitos é que ela limita o número de fluxos simultâneos, porque cada fluxo recebe uma fatia fixa dos recursos disponíveis. Isso é interessante para aplicações que precisam de uma quantidade específica de recursos para funcionarem corretamente, mas há várias aplicações que são _elásticas_, *i.e.*, elas conseguem se adaptar a quantidade de recursos que a rede têm para oferecer em um determinado momento. Um exemplo é uma aplicação de transferência de arquivos: obviamente, gostaríamos que a transferência ocorresse à maior taxa possível, mas a aplicação funciona --- *i.e.*, eventualmente termina a transferência --- a taxa arbitrariamente baixas. Na comutação de circuitos, entretanto, se a parcela fixa de recurso dada a cada fluxo não está disponível, o fluxo simplesmente é rejeitado.

#### Multiplexação

Antes de encerrarmos nossa discussão sobre comutação de circuitos, vamos voltar a um ponto específico: como um mesmo enlace pode transmitir simultaneamente múltiplos fluxos. Originalmente, assumimos que isso poderia ser feito simplesmente criando múltiplos enlaces físicos separados entre cada par de comutadores vizinhos. No entanto, essa solução pode ser inconveniente na prática --- por exemplo, por aumentar a quantidade de cabeamento utilizado. Na prática, podemos usar um tipo de solução chamada de _multiplexação_ para atingir o mesmo objetivo com um único enlace físico.

Genericamente, o termo *multiplexação* se refere ao ato de combinar vários fluxos de informação/sinais separados em um mesmo fluxo compartilhado --- a _demultiplexação_ é o processo inverso. Esse termo aparecerá em outros contextos nessa disciplina, particularmente no início do Capítulo 3. Entretanto, aqui ele denota uma série de técnicas que podem ser utilizadas para combinar diversos fluxos de dados em um mesmo enlace físico. A título de exemplo, veremos superficialmente como funcionam dois métodos de multiplexação: o TDM e o FDM.

O TDM (do inglês *Time-Division Multiplexing*) funciona dividindo o tempo em janelas --- ou *slots*. A cada fluxo alocam-se *slots*, geralmente de forma cíclica (*i.e.*, com $n$ fluxos, define-se um ciclo de $n$ *slots*, um para cada fluxo). Durante o *slot* de um fluxo, seus dados são transmitidos exclusivamente. Assim, a rigor, não há transmissões efetivamente simultâneas no TDM. No entanto, se a duração dos *slots* for suficientemente curta, a transmissão dos fluxos se alterna tão rapidamente que o mesmo efeito prático pode ser atingido[^TDMVsRR]. Se considerarmos um período longo de funcionamento do enlace, cada um dos $n$ fluxos terá recebido aproximadamente $\frac{1}{n}$ da capacidade total do enlace físico.

[^TDMVsRR]: Isso é similar à ideia de escalonamento de processos em um sistema multitarefas. Os processos se alternam utilizando o processador por tempos curtos --- um *quantum* --- dando a impressão ao usuário de que todos os processos estão executando simultaneamente.

Outro método de multiplexação é o FDM (do inglês *Frequency-Division Multiplexing*). Diferentemente do que ocorre no TDM, no FDM os vários fluxos são transmitidos, de fato, ao mesmo tempo. Para isso, o FDM divide o meio físico em _canais_ diferentes, *i.e.*, faixas de frequência distintas que são alocadas a cada fluxo. Não faz parte do escopo dessa disciplina como isso funciona no nível físico, mas apenas como um exemplo mais concreto, o FDM é utilizado para sinais de TV. Tipicamente, os sinais das várias emissoras de TV aberta chega até nossos aparelhos de TV através de um único cabo coaxial. Entretanto, cada emissora possui seu próprio canal, isto é, uma faixa de frequência exclusiva para o seu sinal. Eletronicamente, nossos aparelhos de TV são capazes de isolar o sinal do canal desejado dos demais, interpretando, portanto, apenas o fluxo desejado.

É importante notar, no entanto, embora todos os fluxos sejam transmitidos ao mesmo tempo, o FDM ainda está dividindo a capacidade do enlace entre eles. Ao dividirmos uma faixa de frequência larga em vários canais menores, cada canal terá uma capacidade correspondendo a uma fração daquela da faixa original. Dessa forma, assumindo que a divisão seja feita em canais de mesma largura, cada um dos $n$ canais possuirá $\frac{1}{n}$ da capacidade do enlace original.

## Multiplexação Estatística

